{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxNj-Eepqs7Y"
      },
      "source": [
        "Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h7oKECYTx0Kf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X3yOG7px4aT"
      },
      "source": [
        "Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A8fHUZGTx6Dg"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('syntatical_train_features.csv')\n",
        "df_test = pd.read_csv('syntatical_test_features.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "kk62tAbhx_8Q",
        "outputId": "e6356a0e-bd2a-41b5-bc96-8f8641f3e5b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    40944.000000\n",
              "mean       483.441383\n",
              "std        720.079079\n",
              "min          1.000000\n",
              "25%        343.000000\n",
              "50%        419.000000\n",
              "75%        511.000000\n",
              "max      41901.000000\n",
              "Name: text, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40944.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>483.441383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>720.079079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>343.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>419.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>511.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41901.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_train.text.apply(lambda x: len(x.split(' '))).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh7D-T32ychb"
      },
      "source": [
        "Calculating Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k48cAwN_zDKT",
        "outputId": "068239a7-c831-4b23-bf69-d53293775e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"gpt2-large\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "# model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "# model = model.to(\"cuda\")\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NmoKvpDD_Ts",
        "outputId": "3ed3c564-bf3d-4729-ac73-526d9dcfa3e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40944, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "49YlBDtrhdMW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def calculate_dataset_perplexity(dataset, model_name, max_seq_len=1024, batch_size=100, sliding_window=512):\n",
        "    from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    model.eval()  # Evaluation mode\n",
        "    model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if tokenizer.pad_token is None:\n",
        "      tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        # Pad sequences to the same length\n",
        "        return pad_sequence(batch, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    all_perplexities = []\n",
        "    # i=0\n",
        "    for text in dataset:\n",
        "        # Skip empty or short texts\n",
        "        # print(text)\n",
        "        # i+=1\n",
        "        if len(text.strip()) == 0:\n",
        "            print(\"Skipping empty text\")\n",
        "            continue\n",
        "\n",
        "        # Tokenize the text\n",
        "        chunks = []\n",
        "        tokenized = tokenizer(text, return_tensors=\"pt\", truncation=False)\n",
        "        input_ids = tokenized[\"input_ids\"].squeeze(0)\n",
        "        if len(input_ids) < max_seq_len:\n",
        "            chunks.append(input_ids)\n",
        "        else:\n",
        "          # Sliding window chunks\n",
        "\n",
        "          for i in range(0, len(input_ids) - max_seq_len + 1, sliding_window):\n",
        "              chunks.append(input_ids[i : i + max_seq_len])\n",
        "          if len(input_ids) > max_seq_len:\n",
        "              chunks.append(input_ids[-max_seq_len:])  # Add final chunk\n",
        "\n",
        "        # Create DataLoader for batch processing\n",
        "        dataloader = DataLoader(chunks, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "        text_perplexities = []\n",
        "        for batch in dataloader:\n",
        "            batch = batch.to(\"cuda\")\n",
        "\n",
        "            # Handle padding tokens for labels\n",
        "            labels = batch.clone()\n",
        "            labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "            # Compute loss (cross-entropy)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(batch, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "                # Handle NaN loss\n",
        "                if torch.isnan(loss):\n",
        "                    print(f\"NaN loss encountered for batch. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                # Compute perplexity\n",
        "                perplexity = torch.exp(torch.clamp(loss, max=100))  # Clamp for stability\n",
        "                text_perplexities.append(perplexity.item())\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        if text_perplexities:\n",
        "            # Average perplexity for this text\n",
        "            all_perplexities.append(np.mean(text_perplexities))\n",
        "\n",
        "    if all_perplexities:\n",
        "        # Return average perplexity across the dataset\n",
        "        return np.mean(all_perplexities), all_perplexities\n",
        "    else:\n",
        "        print(\"No valid texts or chunks processed.\")\n",
        "        return float(\"nan\"), []\n"
      ],
      "metadata": {
        "id": "j_CpPEAdBI-s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\"  # Replace with your desired model\n",
        "_, df_train['gpt2_perplexity'] = calculate_dataset_perplexity(\n",
        "    df_train['text'].values, model_name, max_seq_len=1024, batch_size=50, sliding_window=512\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prsYUpZXdLlV",
        "outputId": "34ec8efa-328f-4ac7-8f61-22d226d94f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2031 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\"  # Replace with your desired model\n",
        "_, df_test['gpt2_perplexity'] = calculate_dataset_perplexity(\n",
        "    df_test['text'].values, model_name, max_seq_len=1024, batch_size=100, sliding_window=512\n",
        ")\n"
      ],
      "metadata": {
        "id": "MiCE-1ijW-q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "2Wjj6FCXSRA2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export HUGGING_FACE_HUB_TOKEN=\"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\""
      ],
      "metadata": {
        "id": "Ur01RcpdFA1J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "aFJKW4rLFCoP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-3.2-3B\"\n",
        "\n",
        "_, df_train['llama_perplexity'] = calculate_dataset_perplexity(\n",
        "    df_train['text'].values, model_name, max_seq_len=1024, batch_size=100, sliding_window=512\n",
        ")\n",
        "\n",
        "# model_name = \"gpt2\"  # Replace with your desired model\n",
        "_, df_test['llama_perplexity'] = calculate_dataset_perplexity(\n",
        "    df_test['text'].values, model_name, max_seq_len=1024, batch_size=100, sliding_window=512\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e6e1c5ce8eb24db89221c82a3b973ac2",
            "526030cddbcd4e2f85f0ff72b4511a31",
            "13fcfbe2e6a84aee97ac526a79ea34ba",
            "98d3db92c8704276b8f281f97771c761",
            "a35d46f528664c1788b4647b64c878f5",
            "ab2d24eb6ada433eb0e1b2710299f390",
            "33afb438bb0a4f3b9ebaac83b29f3058",
            "c08fd29896464624b83775f27913f0aa",
            "f4d9a04c467a48e1bf7985d8e5009c57",
            "c854ec3ba50846328297847cf44b48fa",
            "c74ed400a1fc418bb3fe09a4fecf38fe"
          ]
        },
        "id": "NYSpVaiXFGS3",
        "outputId": "e756f46e-1ca9-48cc-adf7-16f22e40cfc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e1c5ce8eb24db89221c82a3b973ac2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKboL02o5eoZ"
      },
      "source": [
        "Calculate Burstiness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQLLOqaV09nr"
      },
      "outputs": [],
      "source": [
        "def calculate_burstiness(model_name,text,window_size=1024,stride=512):\n",
        "    tockenizer =  AutoTokenizer.from_pretrained(model_name)\n",
        "    tokens = tokenizer.encode(text)\n",
        "    overall_counts = Counter(tokens)\n",
        "    overall_freq = {token: count / len(tokens) for token, count in overall_counts.items()}\n",
        "\n",
        "    burstiness_scores = []\n",
        "    for start_indx in range(0,len(tokens),stride):\n",
        "        end_indx = min(start_indx+window_size,len(tokens))\n",
        "        window_tokens = tokens[start_indx:end_indx]\n",
        "        window_counts = Counter(window_tokens)\n",
        "        window_freq = {token: count / len(window_tokens) for token, count in window_counts.items()}\n",
        "\n",
        "        burstiness = sum(abs(overall_freq.get(token, 0) - window_freq.get(token, 0)) for token in window_freq)\n",
        "        burstiness_scores.append(burstiness)\n",
        "    return np.mean(burstiness_scores)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32fu1vhY531A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyN3O4QjGxAkZU0ZZm/TAMic"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6e1c5ce8eb24db89221c82a3b973ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_526030cddbcd4e2f85f0ff72b4511a31",
              "IPY_MODEL_13fcfbe2e6a84aee97ac526a79ea34ba",
              "IPY_MODEL_98d3db92c8704276b8f281f97771c761"
            ],
            "layout": "IPY_MODEL_a35d46f528664c1788b4647b64c878f5"
          }
        },
        "526030cddbcd4e2f85f0ff72b4511a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab2d24eb6ada433eb0e1b2710299f390",
            "placeholder": "​",
            "style": "IPY_MODEL_33afb438bb0a4f3b9ebaac83b29f3058",
            "value": "Loading checkpoint shards:  50%"
          }
        },
        "13fcfbe2e6a84aee97ac526a79ea34ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c08fd29896464624b83775f27913f0aa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4d9a04c467a48e1bf7985d8e5009c57",
            "value": 1
          }
        },
        "98d3db92c8704276b8f281f97771c761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c854ec3ba50846328297847cf44b48fa",
            "placeholder": "​",
            "style": "IPY_MODEL_c74ed400a1fc418bb3fe09a4fecf38fe",
            "value": " 1/2 [00:25&lt;00:25, 25.33s/it]"
          }
        },
        "a35d46f528664c1788b4647b64c878f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab2d24eb6ada433eb0e1b2710299f390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33afb438bb0a4f3b9ebaac83b29f3058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c08fd29896464624b83775f27913f0aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4d9a04c467a48e1bf7985d8e5009c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c854ec3ba50846328297847cf44b48fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74ed400a1fc418bb3fe09a4fecf38fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}